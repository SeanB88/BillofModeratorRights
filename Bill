
The Content Moderator’s Bill of Rights
Version: 1.0 (The Burke Protocols)
License: Creative Commons Attribution-ShareAlike 4.0 (CC BY-SA 4.0)
Preamble: The "Sineaters " Manifesto
We are the "Online Janitors or Modern Sineaters". We clean the digital crime scenes so the public never has to see the blood or Sineaters taking in every vile act or opinion ever said by the general public as unbiased as we can take . We deal with death, killing, hate groups, and child exploitation, acting as the filter for the collective darkness of humanity.
For too long, large platforms have used the rhetoric of "Soldiers in the Trenches" to demand loyalty, yet treated us like "Soldiers of Fortune"—mercenaries hired by third-party contractors to keep their hands clean. We are told we are essential to the "Greater Good," yet we are treated as "replaceable ghosts in a machine". After our time we simply let go as former shadows of ourselves either completely numb to every dark web content or scarred and left to deal with deal with our wounds as we begin to fight for another job to pay the bills

We reject the "MLM-style" group-think that demands cult-like devotion while offering zero security. We reject "Wellness Theater"—coloring books and yoga—as a substitute for medical care. We assert that human psychological safety is a non-negotiable right, not a perk.
This Bill of Rights establishes the minimum ethical standard for the employment of Content Moderators worldwide.
1. The "Crime Scene" Nature of the Work
Moderators are not just reviewers; they are digital crime scene cleaners dealing with death, killing, hate groups, beastiality, and child exploitation. Unlike traditional first responders, moderators are "replaceable ghosts in a machine" who deal with the aftermath of conspiracies and political discourse that are quickly forgotten by the public but linger in the moderator's mind.
2. The Manipulation of the "Political Compass"
Constant exposure to emotional, click-driven political content (e.g., clickfarm articles, fringe/alt news) causes a moderator's own political compass to "screw up". The job forces a cold, formulaic approach to hate, leading to a loss of initial decency and perspective. And now in the modern era even the biggest organisations were flawed back then are now more pressured by money and biases.
3. The "Soldiers in the Trenches" Fallacy
Big Tech utilizes "MLM-style" group-think—using terms like "the greater good" or "soldiers in the trenches"—to manufacture loyalty. In reality, the moderator is an isolated cog whose confidence and social life are subsumed by the role, only to be discarded if quality metrics (AHT/Accuracy) dip. Unless you were a part of the inner circle of employees internally, Outsourced employees are necessarily needed but isolated from any benefit, privelege sometimes with a greater workload and worse working conditions but fed the same lines. A moderator can be training to do grooming queues or training the ai system for pedophiles while damaging their minds in the process. Once let go with little to no help or support. Most companies tell and repeat to their teams not to discuss or tell anyone outside the content they have to watch or review. All clients and companies should help provide a barrier from work and a clear exit plan for employees after 4 months on the job. 



Article I: The Right to Psychological Safety & Medical Reality
1.1. Clinical Support Over "Wellness Theater"
Wellness coaches and Counsellors are not prepared for the trauma dumping
They are trained to deal with common issues, stress from work, bills, finance etc. It is very normal and crucial for a normal work environment but moderators' jobs are different.
Moderators viewing high-impact trauma (e.g., gore, CSAM, torture) have the right to access external, licensed clinical psychologists. In-house "wellness coaches" or "resilience training" (e.g., painting, games) cannot be used as a substitute for medical care. The provider must be independent of the employer to ensure patient confidentiality and trust.
1.2. The "Stress Test" & Informed Consent
No moderator shall be deployed to a live queue without a mandatory "Stress Test" week. Most moderators just go through training and go into the queues.Training on how to mentally deal with extreme content 90% of your week. Recruits must be fully exposed to the nature of the content (simulated or historical data) before signing a binding contract, ensuring true informed consent regarding the psychological risks.
1.3. Mandatory Decompression
Moderators have the right to "Decompression Time" immediately following exposure to severe traumatic content. This time is "on the clock" and distinct from standard breaks.
Article II: The Right to Circadian Justice & Social Connection
2.1. Prohibition of Permanent Night Shifts
To prevent the "Social Death" associated with long-term isolation, no moderator shall be contractually bound to a permanent night shift for a period exceeding six (6) months. Employers must offer a "Rotation Option" to daylight hours. This is very doable a lot of nurses , police enforcement and Engineers in datacentres usually get a system where they work 2 weeks at night then switch of similar effect
2.2. Social Reintegration Hours
Recognizing that the role creates "social isolation", night-shift workers are entitled to "Flexi-Hours" or "Daylight Credits"—paid time off specifically designed to allow attendance at social, family, or community events during normal waking hours.
Article III: The Right to Contextual Judgment (Anti-Rigidity)
3.1. The "Human Margin" of Error
Moderators shall not be terminated or penalized for accuracy dips below rigid thresholds (e.g., 98%) when processing high-trauma queues. A "Safety Margin" must be applied to acknowledge the cognitive toll of processing horror. A moderator should not have to marked poorly over minor errors for example lose percentage over removing nerf products or pellets sold on the platform if gore , violence , hatespeech etc is taken care of
3.2. Freedom from Binary Absolutism
Moderators have the right to exercise human judgment over binary AI training rules. If a "binary definition" of hate or violence contradicts the context, the moderator has the right to "Flag for Nuance" without it counting as an error.
Hate groups and people can and will constantly take benign symbols and warp them . Things must be taken in contest 
3.3. The "Algorithmic Speed-Trap" Protection
Productivity metrics (Average Handling Time) must be weighted by severity. A decision regarding Child Sexual Abuse Material (CSAM) or terrorism cannot be held to the same speed standard as a spam ticket.
Article IV: The Right to Cognitive Autonomy
4.1. Protection from Institutional "Group-Think"
Moderators have the right to "Neutrality Training" and external reality checks to prevent the warping of their political compass. Employers are prohibited from using coercive "cult-like" language (e.g., "saving the world," "family") to discourage workers from reporting unsafe conditions. In the end even if outsourced we are all expendable to them
4.2. Whistleblower & Transparency Protection
Moderators retain the right to document their own "Exposure Logs" (redacted for user privacy) as personal medical records. NDAs cannot be enforced to prevent a moderator from discussing the nature of their trauma with medical professionals or legal counsel.
No employer should use personal chats with another employee as a response to whistleblowing especially if it mentions trauma or burnt out.
4.3. Reference Portability: Employers must provide references that acknowledge the unique skills of the role, helping moderators overcome the "negative implications" and HR biases they face when trying to find work after the position.
Section III: The Open Source Implementation

Article V: The Right to Dignified Exit & Career Continuity
5.1. The "Clean Exit" Protocol
Upon completion of service (minimum 6 months), moderators are entitled to a "Cool-Down Period". This includes access to career counseling and "re-skilling" support to bridge the "employment disconnect" and transition into a non-traumatic workspace.
5.2. Fair Referencing
Employers must provide references that acknowledge the skills acquired (crisis management, policy enforcement) rather than generic confirmations of employment, protecting workers from the stigma often associated with "content moderation" on a CV.
Appendix: Implementation & Open Source



Status: Living Document
Repository: [Link to GitHub/Codeberg]
Contribution Guidelines:
This document is Open Source. We invite moderators from all platforms (Reddit, Discord, TikTok, Meta) to submit "Pull Requests" to add modules specific to their platforms.
Modules:
 * Module A: The "Sean Burke" Clause – Specific protections for contractors in Ireland.
 * Module B: The "Gig Economy" Clause – Protections for unpaid/volunteer mods.
 * Module C: The "AI Training" Clause – Rights regarding the use of mod decisions to train generative AI.

